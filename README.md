ðŸš€ NebulaFlowEngine â€“ Tredence AI Engineering Assignment

NebulaFlowEngine is a modular and extensible workflow/graph execution engine built with FastAPI and Python, designed as part of the Tredence AI Engineering Assignment.
It demonstrates how to build:

A minimal, reusable workflow engine

State-driven node execution

Conditional routing & looping

Tool registries

Clean API interfaces

A complete example workflow (Option B: Summarization + Refinement) as required in the assignment.

This project uses a unique naming theme (NebulaFlow + Aurora workflow) but follows exactly the functional requirements specified in the assignment.
Key Features
ðŸ”¹ 1. FlowMap Graph Engine

Defines workflows as graphs:

Nodes â†’ specific processing steps

Edges â†’ transitions between steps

Start node â†’ entry point

Simple and powerful design using Python dictionaries.

ðŸ”¹ 2. NebulaTools Registry

All node functions (tools) are registered globally.

Tools operate on and update a shared state dictionary.

ðŸ”¹ 3. State-Based Execution

Every node receives and returns the same state dictionary.

State evolves as the workflow progresses.

Looping/branching handled through state["stop"].

ðŸ”¹ 4. In-Memory Runtime

Stores:

Graphs (graph_id)

Workflow runs (run_id)

Current node, full state, and execution log

ðŸ”¹ 5. FastAPI Endpoints

REST APIs as required:

POST /graph/create â€“ Create a new workflow graph

POST /graph/run â€“ Run a graph end-to-end

GET /graph/state/{run_id} â€“ Inspect current state & logs

GET /health â€“ Simple health check

POST /aurora/run â€“ Run the Option-B summarization workflow

ðŸ”¹ 6. Example Workflow (Option B â€“ Summarization + Refinement)

Implements the exact sequence required in the assignment:

Split text into chunks

Generate chunk summaries

Merge summaries
Architecture OverviewNebulaFlowEngine/
â”‚
â”œâ”€â”€ starlight_api/
â”‚   â”œâ”€â”€ main.py                   # FastAPI app & endpoints
â”‚   â”‚
â”‚   â”œâ”€â”€ comet_engine/
â”‚   â”‚   â”œâ”€â”€ graph_core.py         # Engine executor
â”‚   â”‚   â”œâ”€â”€ tool_registry.py      # Global registry for tools
â”‚   â”‚   â””â”€â”€ state_kernel.py       # In-memory graphs & runs
â”‚   â”‚
â”‚   â”œâ”€â”€ data_models/
â”‚   â”‚   â””â”€â”€ nebula_schemas.py     # Pydantic models
â”‚   â”‚
â”‚   â””â”€â”€ orbits/
â”‚       â””â”€â”€ summary_orbit.py      # Option-B workflow tools + graph
â”‚
â””â”€â”€ README.md
How to Run the Project Locally
1ï¸âƒ£ Install Dependencies
pip install fastapi "uvicorn[standard]" pydantic

2ï¸âƒ£ Run the API Server
python -m uvicorn starlight_api.main:app --reload

3ï¸âƒ£ Verify the Server

Health Check
ðŸ‘‰ http://127.0.0.1:8000/health

Response:

{ "status": "NebulaFlow is online" }


Full API Documentation (Swagger UI)
ðŸ‘‰ http://127.0.0.1:8000/docs

Alternative Documentation (ReDoc)
ðŸ‘‰ http://127.0.0.1:8000/redoc

ðŸŒŸ Option B Workflow (AuroraText Condenser)

This is the required sample workflow from the assignment.

Workflow Nodes
Node	Tool Name	Purpose
ShardSplitter	shard_splitter	Splits input text into chunks
EchoSummoner	echo_summoner	Creates mini-summaries
FusionWeaver	fusion_weaver	Merges mini-summaries
ClarityPulse	clarity_pulse	Cleans/refines summary
ThresholdGate	threshold_gate	Loop decision (stop or refine)
Loop Logic

If len(final_summary) > summary_limit, engine loops:

ThresholdGate â†’ ClarityPulse â†’ ThresholdGate â†’ ...


Loop ends when:

state["stop"] = True

 How to Run Option B Workflow

Use Swagger UI /docs or send a POST request to:

POST /aurora/run
Example Body:
{
  "input_text": "Paste any long article or paragraph here...",
  "summary_limit": 250
}

Example Output:

final_state.final_summary â€“ refined summary

run_id â€“ execution ID

log â€“ detailed node-by-node trace

Generic Graph Engine Usage
Create a Graph Manually

POST /graph/create

{
  "name": "MyFlow",
  "nodes": {
    "Start": "shard_splitter",
    "Next": "echo_summoner"
  },
  "edges": {
    "Start": "Next"
  },
  "start_node": "Start"
}

Run That Graph

POST /graph/run

{
  "graph_id": "returned_graph_id_here",
  "initial_state": {
    "input_text": "Hello world!"
  }
}

Check Run State

GET /graph/state/{run_id}

Why This Project Meets the Assignment Requirements

This backend satisfies all core requirements in the assignment summary:

Minimal workflow / graph engine âœ”

Nodes with shared state âœ”

Edges defining transitions âœ”

Branching & looping âœ”

Tool registry âœ”

FastAPI endpoints âœ”

Complete example workflow (Option B) âœ”

Clean, modular folder structure âœ”

What Can Be Improved With More Time

Add database persistence instead of in-memory runtime

Add async support for long-running tools

Add WebSocket live log streaming

Add dynamic branching rules in JSON format

Add more sample workflows (e.g., code review, anomaly detection)

Conclusion

NebulaFlowEngine showcases a clean and extensible approach to workflow orchestration using Python and FastAPI.
It meets the assignmentâ€™s functional requirements while offering a unique naming system and modular architecture ideal for showcasing backend engineering capability.

Refine the summary

Loop until under a length threshold
